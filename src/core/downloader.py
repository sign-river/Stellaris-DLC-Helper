#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½æ¨¡å—
è´Ÿè´£ä¸‹è½½DLCæ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œæ™ºèƒ½é€Ÿåº¦ç›‘æ§
"""

import os
import time
import requests
from ..config import REQUEST_TIMEOUT, CHUNK_SIZE, RETRY_TIMES
from ..utils import PathUtils


class SpeedTooSlowException(Exception):
    """é€Ÿåº¦è¿‡æ…¢å¼‚å¸¸ï¼Œç”¨äºè§¦å‘æ™ºèƒ½åˆ‡æº"""
    def __init__(self, message, new_url, new_source):
        super().__init__(message)
        self.new_url = new_url
        self.new_source = new_source


class DLCDownloader:
    """DLCä¸‹è½½å™¨ç±»"""
    
    def __init__(self, progress_callback=None):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        
        å‚æ•°:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(percent, downloaded, total)
        """
        from ..config import SPEED_MONITOR_ENABLED
        
        self.progress_callback = progress_callback
        self.paused = False  # æš‚åœæ ‡å¿—
        self.stopped = False  # åœæ­¢æ ‡å¿—
        
        # åˆ›å»ºSourceManagerå®ä¾‹ç”¨äºæ£€æŸ¥å¯ç”¨çš„æº
        from .source_manager import SourceManager
        self.source_manager = SourceManager()
        
        # å…¨å±€é…ç½®
        self._speed_monitor_enabled = SPEED_MONITOR_ENABLED  # ä»é…ç½®è¯»å–
        self._speed_check_interval = 3.0  # é€Ÿåº¦æ£€æŸ¥é—´éš”ï¼ˆ3ç§’ï¼‰
        
        # DLCçº§åˆ«çš„çŠ¶æ€ï¼ˆæ¯æ¬¡ä¸‹è½½æ—¶é‡ç½®ï¼‰
        self._current_dlc_state = None  # å½“å‰DLCçš„ä¸‹è½½çŠ¶æ€
        
        # åˆ›å»ºä¼šè¯ä»¥å¤ç”¨è¿æ¥
        self.session = requests.Session()
        # è®¾ç½®åˆç†çš„è¶…æ—¶å’Œé‡è¯•
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10,
            pool_maxsize=10,
            max_retries=0,  # æˆ‘ä»¬è‡ªå·±å¤„ç†é‡è¯•
            pool_block=False
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
        
    def pause(self):
        """æš‚åœä¸‹è½½"""
        self.paused = True
    
    def resume(self):
        """æ¢å¤ä¸‹è½½"""
        self.paused = False
    
    def stop(self):
        """åœæ­¢ä¸‹è½½"""
        self.stopped = True
        self.paused = False
        # æ³¨æ„ï¼šä¸åœ¨ stop ä¸­å…³é—­ sessionï¼Œè¿™æ ·å¯åœ¨åˆ‡æ¢åè¿›è¡Œé‡è¯•
        # å¦‚æœéœ€è¦å½»åº•é‡Šæ”¾èµ„æºï¼Œè¯·è°ƒç”¨ close()

    def close(self):
        """å½»åº•å…³é—­ä¸‹è½½å™¨å¹¶é‡Šæ”¾ä¼šè¯"""
        if hasattr(self, 'session'):
            try:
                self.session.close()
            except Exception:
                pass
    
    def _init_dlc_download_state(self):
        """åˆå§‹åŒ–å•ä¸ªDLCçš„ä¸‹è½½çŠ¶æ€ï¼ˆæ¯æ¬¡ä¸‹è½½DLCå‰è°ƒç”¨ï¼‰"""
        self._current_dlc_state = {
            'speed_samples': [],  # é€Ÿåº¦é‡‡æ · [(timestamp, bytes_downloaded), ...]
            'last_speed_check_time': 0,  # ä¸Šæ¬¡é€Ÿåº¦æ£€æŸ¥æ—¶é—´
            'slow_speed_duration': 0,  # æ…¢é€ŸæŒç»­æ—¶é—´
            'download_start_time': time.time(),  # DLCä¸‹è½½å¼€å§‹æ—¶é—´
            'last_data_time': time.time(),  # æœ€åä¸€æ¬¡æ”¶åˆ°æ•°æ®çš„æ—¶é—´
            'total_downloaded': 0,  # å½“å‰DLCå·²ä¸‹è½½çš„æ€»å­—èŠ‚æ•°
        }
    
    def _reset_dlc_download_state(self):
        """é‡ç½®DLCä¸‹è½½çŠ¶æ€ï¼ˆåˆ‡æ¢æºæ—¶è°ƒç”¨ï¼‰"""
        if self._current_dlc_state:
            self._current_dlc_state['speed_samples'] = []
            self._current_dlc_state['last_speed_check_time'] = time.time()
            self._current_dlc_state['slow_speed_duration'] = 0
            self._current_dlc_state['last_data_time'] = time.time()
    
    def _check_speed_and_switch(self, current_downloaded, current_time, fallback_urls, current_source_name):
        """
        æ£€æŸ¥ä¸‹è½½é€Ÿåº¦ï¼Œå¦‚æœè¿‡æ…¢åˆ™è¿”å›å»ºè®®åˆ‡æ¢çš„æºï¼ˆåŸºäºå½“å‰DLCçš„çŠ¶æ€ï¼‰
        
        å‚æ•°:
            current_downloaded: å½“å‰DLCå·²ä¸‹è½½å­—èŠ‚æ•°ï¼ˆä»…æœ¬æ¬¡å°è¯•ï¼‰
            current_time: å½“å‰æ—¶é—´æˆ³
            fallback_urls: å¤‡ç”¨URLåˆ—è¡¨
            current_source_name: å½“å‰æºåç§°
            
        è¿”å›:
            tuple: (should_switch, new_url, new_source_name) æˆ– (False, None, None)
        """
        if not self._speed_monitor_enabled or not fallback_urls or not self._current_dlc_state:
            return False, None, None
        
        state = self._current_dlc_state
        
        # æ·»åŠ é€Ÿåº¦é‡‡æ ·ç‚¹ï¼ˆä½¿ç”¨DLCçº§åˆ«çš„æ€»ä¸‹è½½é‡ï¼‰
        state['speed_samples'].append((current_time, state['total_downloaded']))
        
        # åªä¿ç•™æœ€è¿‘60ç§’çš„é‡‡æ ·
        cutoff_time = current_time - 60
        state['speed_samples'] = [(t, b) for t, b in state['speed_samples'] if t >= cutoff_time]
        
        # éœ€è¦è‡³å°‘10ç§’çš„æ•°æ®æ‰èƒ½åˆ¤æ–­
        if len(state['speed_samples']) < 2:
            return False, None, None
        
        time_span = current_time - state['speed_samples'][0][0]
        if time_span < 10:
            return False, None, None
        
        # è®¡ç®—å¹³å‡é€Ÿåº¦ï¼ˆMB/sï¼‰
        bytes_delta = state['total_downloaded'] - state['speed_samples'][0][1]
        avg_speed_mb = (bytes_delta / 1024 / 1024) / time_span
        
        # æ£€æŸ¥é€Ÿåº¦é˜ˆå€¼ï¼ˆè€ƒè™‘Giteeç¨³å®š2-3 MB/sï¼‰
        # å¦‚æœé€Ÿåº¦æŒç»­ä½äº1.0 MB/sï¼ˆä½äºGiteeä¸‹é™ï¼‰ï¼ŒæŒç»­20ç§’ä»¥ä¸Š
        SLOW_THRESHOLD = 1.0  # MB/s
        SLOW_DURATION_THRESHOLD = 20  # ç§’
        
        if avg_speed_mb < SLOW_THRESHOLD:
            state['slow_speed_duration'] += (current_time - state['last_speed_check_time'])
            
            if state['slow_speed_duration'] >= SLOW_DURATION_THRESHOLD:
                # é€Ÿåº¦è¿‡æ…¢ï¼Œéœ€è¦åˆ‡æº
                # æ£€æŸ¥æ˜¯å¦åœ¨ç¼“å­˜æœ‰æ•ˆæœŸå†…ï¼ˆ5åˆ†é’Ÿï¼‰
                current_timestamp = time.time()
                cache_valid = False
                
                if hasattr(self.source_manager, '_last_best_timestamp'):
                    cache_age = current_timestamp - self.source_manager._last_best_timestamp
                    if cache_age < self.source_manager._cache_validity:
                        cache_valid = True
                
                if cache_valid:
                    # ä½¿ç”¨ç¼“å­˜çš„é€Ÿåº¦ä¿¡æ¯é€‰æ‹©æ¬¡ä¼˜æº
                    speed_cache = getattr(self.source_manager, '_speed_cache', {})
                    available_sources = []
                    
                    for url, source_name in fallback_urls:
                        if source_name != current_source_name and source_name in speed_cache:
                            speed, _ = speed_cache[source_name]
                            available_sources.append((speed, url, source_name))
                    
                    if available_sources:
                        # é€‰æ‹©ç¼“å­˜ä¸­é€Ÿåº¦æœ€å¿«çš„æº
                        available_sources.sort(key=lambda x: x[0], reverse=True)
                        best_speed, best_url, best_source = available_sources[0]
                        
                        # åªæœ‰å½“å¤‡é€‰æºé€Ÿåº¦æ˜æ˜¾æ›´å¿«æ—¶æ‰åˆ‡æ¢ï¼ˆè‡³å°‘å¿«50%ï¼‰
                        if best_speed > avg_speed_mb * 1.5:
                            self._log_message(f"âš ï¸ æ£€æµ‹åˆ°é€Ÿåº¦è¿‡æ…¢ ({avg_speed_mb:.2f} MB/s)ï¼Œåˆ‡æ¢åˆ°æ›´å¿«çš„æº: {best_source} (ç¼“å­˜é€Ÿåº¦: {best_speed:.2f} MB/s)")
                            self._reset_dlc_download_state()  # é‡ç½®DLCçº§åˆ«çŠ¶æ€
                            return True, best_url, best_source
                else:
                    # ç¼“å­˜è¿‡æœŸï¼Œé‡æ–°æµ‹é€Ÿé€‰æ‹©æœ€ä½³æº
                    self._log_message(f"âš ï¸ æ£€æµ‹åˆ°é€Ÿåº¦è¿‡æ…¢ ({avg_speed_mb:.2f} MB/s)ï¼Œé‡æ–°æµ‹é€Ÿé€‰æ‹©æœ€ä½³æº...")
                    
                    try:
                        # ä½¿ç”¨ç¼“å­˜æœºåˆ¶é¿å…é¢‘ç¹æµ‹é€Ÿ
                        best_source, test_url = self.source_manager.get_best_download_source(
                            silent=False,
                            log_callback=self._get_log_callback(),
                            force_retest=False  # ä½¿ç”¨ç¼“å­˜
                        )
                        
                        # ä»fallback_urlsä¸­æ‰¾åˆ°å¯¹åº”çš„URL
                        for url, source_name in fallback_urls:
                            if source_name == best_source:
                                self._log_message(f"âœ… åˆ‡æ¢åˆ°æµ‹é€Ÿæœ€ä¼˜æº: {best_source}")
                                self._reset_dlc_download_state()  # é‡ç½®DLCçº§åˆ«çŠ¶æ€
                                return True, url, best_source
                    except Exception as e:
                        self._log_message(f"âŒ é‡æ–°æµ‹é€Ÿå¤±è´¥: {e}")
        else:
            # é€Ÿåº¦æ­£å¸¸ï¼Œé‡ç½®æ…¢é€Ÿè®¡æ—¶å™¨
            state['slow_speed_duration'] = 0
            state['slow_speed_duration'] = 0
        
        state['last_speed_check_time'] = current_time
        return False, None, None
    
    def _log_message(self, message):
        """è¾“å‡ºæ—¥å¿—æ¶ˆæ¯"""
        print(message)
        if self.progress_callback and hasattr(self.progress_callback, 'log_message'):
            try:
                self.progress_callback.log_message(message)
            except Exception:
                pass
    
    def _get_log_callback(self):
        """è·å–æ—¥å¿—å›è°ƒå‡½æ•°"""
        if self.progress_callback and hasattr(self.progress_callback, 'log_message'):
            return self.progress_callback.log_message
        return None
    
    def download(self, url, dest_path, fallback_urls=None, expected_hash: str = None, primary_source_name: str = None):
        """
        ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ã€é‡è¯•ã€å¤šæºfallbackå’Œæ™ºèƒ½é€Ÿåº¦ç›‘æ§åˆ‡æºï¼‰
        
        å‚æ•°:
            url: ä¸»ä¸‹è½½URL
            dest_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
            fallback_urls: å¤‡ç”¨URLåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸ
            
        æŠ½å‡º:
            Exception: ä¸‹è½½å¤±è´¥
        """
        # åˆå§‹åŒ–å½“å‰DLCçš„ä¸‹è½½çŠ¶æ€
        self._init_dlc_download_state()
        
        # ä½¿ç”¨æ‰€æœ‰URLï¼Œä½†åªå°è¯•å¯ç”¨çš„æº
        urls_to_try = []
        # æ·»åŠ ä¸» URLï¼ˆå¦‚æœæŒ‡å®š primary_source_nameï¼Œåˆ™é™„å¸¦æºåç§°ï¼‰
        if primary_source_name:
            urls_to_try.append((url, primary_source_name))
        else:
            urls_to_try.append((url, None))

        if fallback_urls:
            # æ£€æŸ¥å“ªäº›æºæ˜¯å¯ç”¨çš„
            enabled_source_names = set()
            if hasattr(self, 'source_manager') and self.source_manager:
                enabled_sources = self.source_manager.get_enabled_sources()
                enabled_source_names = {s.get("name") for s in enabled_sources}
            
            # åªæ·»åŠ å¯ç”¨çš„æº
            for url, source_name in fallback_urls:
                if source_name in enabled_source_names:
                    urls_to_try.append((url, source_name))
        
        # å¦‚æœæ²¡æœ‰å¯ç”¨çš„æºå¯ç”¨ï¼ˆæŒ‰ enable æ£€æŸ¥ï¼‰ï¼Œç¡®ä¿æœ‰ perferred main urlå°è¯•
        if not urls_to_try:
            urls_to_try = [(url, primary_source_name or "domestic_cloud")]  # é»˜è®¤ä½¿ç”¨å›½å†…äº‘
        
        last_exception = None
        
        # å°è¯•æ¯ä¸ªURL
        for current_url, source_name in urls_to_try:
            try:
                print(f"å°è¯•ä» {source_name} ä¸‹è½½...")
                # è®°å½•å®Œæ•´ URL åˆ°æ—¥å¿—ï¼ˆæœ‰åŠ©äºè°ƒè¯• URL æ˜ å°„æ˜¯å¦æ­£ç¡®ï¼‰
                print(f"å°è¯• URL: {current_url}")
                # å¦‚æœæœ‰UIå›è°ƒï¼Œæ›´æ–°å½“å‰ä¸‹è½½æºæ˜¾ç¤º
                if hasattr(self, 'progress_callback') and self.progress_callback:
                    # ç¡®ä¿progress_callbackå·²åˆå§‹åŒ–
                    if not hasattr(self.progress_callback, 'update_source'):
                        # è°ƒç”¨ä¸€æ¬¡progress_callbackæ¥åˆå§‹åŒ–å®ƒ
                        try:
                            self.progress_callback(0, 0, 100)
                        except:
                            pass  # å¿½ç•¥åˆå§‹åŒ–é”™è¯¯
                    
                    # ç°åœ¨è°ƒç”¨update_source
                    if hasattr(self.progress_callback, 'update_source'):
                        # æºåç§°æ˜ å°„ä¸ºç”¨æˆ·å‹å¥½çš„æ˜¾ç¤ºåç§°
                        display_name = {
                            "r2": "R2äº‘å­˜å‚¨",
                            "domestic_cloud": "å›½å†…äº‘æœåŠ¡å™¨", 
                            "gitee": "Gitee",
                            "github": "GitHub"
                        }.get(source_name, source_name)
                        self.progress_callback.update_source(display_name)
                
                # å°è¯•ä¸‹è½½ï¼ˆå¯èƒ½æŠ›å‡ºSpeedTooSlowExceptionï¼‰
                result = self._download_single_attempt(current_url, dest_path, fallback_urls, source_name)
                
                # éªŒè¯å“ˆå¸Œï¼ˆå¦‚æœæä¾›ï¼‰
                if result and expected_hash:
                    try:
                        ok = self._verify_file_hash(dest_path, expected_hash)
                        if not ok:
                            # æ ¡éªŒå¤±è´¥ï¼Œè®°å½•å¹¶æŠ›å‡ºé”™è¯¯ä»¥ä¾¿ trigger fallback
                            raise Exception("æ ¡éªŒå¤±è´¥: æ–‡ä»¶å“ˆå¸Œä¸æœŸæœ›å€¼ä¸åŒ¹é…")
                        # æ ¡éªŒé€šè¿‡æ—¥å¿—
                        try:
                            if hasattr(self, 'progress_callback') and getattr(self.progress_callback, 'log_message', None):
                                self.progress_callback.log_message(f"æ–‡ä»¶æ ¡éªŒé€šè¿‡: {dest_path}")
                        except Exception:
                            pass
                    except Exception as e:
                        # åˆ é™¤é”™è¯¯æ–‡ä»¶å¹¶å°è¯•ä¸‹ä¸€æº
                        try:
                            if os.path.exists(dest_path):
                                os.remove(dest_path)
                        except Exception:
                            pass
                        raise
                return result
            except SpeedTooSlowException as e:
                # é€Ÿåº¦è¿‡æ…¢ï¼Œæ™ºèƒ½åˆ‡æ¢åˆ°å»ºè®®çš„æº
                self._log_message(f"ğŸ’¨ {str(e)}")
                # å°†å»ºè®®çš„æºæ’å…¥åˆ°å°è¯•åˆ—è¡¨çš„æœ€å‰é¢ï¼ˆä¸‹æ¬¡å¾ªç¯æ—¶ä½¿ç”¨ï¼‰
                suggested_url = e.new_url
                suggested_source = e.new_source
                
                # ä»urls_to_tryä¸­ç§»é™¤å·²å°è¯•çš„å½“å‰æº
                remaining_urls = [(u, s) for u, s in urls_to_try if s != source_name]
                
                # å°†å»ºè®®æºæ’å…¥åˆ°æœ€å‰é¢
                urls_to_try = [(suggested_url, suggested_source)] + remaining_urls
                
                # ç»§ç»­ä¸‹ä¸€è½®å°è¯•
                last_exception = e
                continue
            except Exception as e:
                last_exception = e
                print(f"ä» {source_name} ä¸‹è½½å¤±è´¥: {str(e)}")
                if (current_url, source_name) != urls_to_try[-1]:  # ä¸æ˜¯æœ€åä¸€ä¸ªURL
                    print("å°è¯•ä¸‹ä¸€ä¸ªæº...")
                    continue
        
        # æ‰€æœ‰URLéƒ½å¤±è´¥äº†
        raise Exception(f"æ‰€æœ‰ä¸‹è½½æºéƒ½å¤±è´¥ï¼Œæœ€åä¸€æ¬¡é”™è¯¯: {str(last_exception)}")
    
    def _download_single_attempt(self, url, dest_path, fallback_urls=None, current_source_name=None):
        """
        å•æ¬¡ä¸‹è½½å°è¯•ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        å‚æ•°:
            url: ä¸‹è½½URL
            dest_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
            fallback_urls: å¤‡ç”¨URLåˆ—è¡¨ï¼ˆç”¨äºé€Ÿåº¦ç›‘æ§åˆ‡æºï¼‰
            current_source_name: å½“å‰æºåç§°
            
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸ
            
        æŠ›å‡º:
            Exception: ä¸‹è½½å¤±è´¥
            SpeedTooSlowException: é€Ÿåº¦è¿‡æ…¢éœ€è¦åˆ‡æº
        """
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(dest_path), exist_ok=True)
        
        # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        temp_path = dest_path + ".tmp"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ä¸‹è½½ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
        downloaded = 0
        if os.path.exists(temp_path):
            downloaded = os.path.getsize(temp_path)
        
        # åœ¨å°è¯•ç»­ä¼ å‰ï¼Œæ£€æŸ¥å½“å‰ URL æ˜¯å¦æ”¯æŒ Range è¯·æ±‚ï¼Œä¸”æ–‡ä»¶å¤§å°ä¸€è‡´
        def _head_check_resume(u, current_downloaded):
            try:
                head = self.session.head(u, timeout=REQUEST_TIMEOUT, allow_redirects=True)
                if head.status_code not in (200, 206):
                    return None
                cl = head.headers.get('Content-Length')
                accept_ranges = head.headers.get('Accept-Ranges', '')
                if cl is not None:
                    try:
                        remote_size = int(cl)
                    except Exception:
                        remote_size = None
                else:
                    remote_size = None

                # å¦‚æœ remote_size is set and remote_size < current_downloaded => mismatch
                if remote_size is not None and remote_size < current_downloaded:
                    # è¿œç«¯æ¯”æœ¬åœ°çŸ­ï¼šä¸ä¸€è‡´
                    try:
                        if self.progress_callback and hasattr(self.progress_callback, 'log_message'):
                            self.progress_callback.log_message(f"è¿œç«¯æ–‡ä»¶å¤§å°({remote_size})æ¯”æœ¬åœ°å·²ä¸‹è½½({current_downloaded})å°ï¼Œæ— æ³•ç»§ç»­ç»­ä¼ ")
                    except Exception:
                        pass
                    return False

                # if server supports ranges it's more safe to resume
                if 'bytes' in accept_ranges.lower():
                    try:
                        if self.progress_callback and hasattr(self.progress_callback, 'log_message'):
                            self.progress_callback.log_message("è¿œç«¯æ”¯æŒ Rangeï¼Œå‡†å¤‡å¼€å§‹ç»­ä¼ ")
                    except Exception:
                        pass
                    return True

                # If content-length exists and remote_size >= current_downloaded but no Accept-Ranges
                if remote_size is not None and remote_size >= current_downloaded:
                    # We can attempt to resume by issuing a ranged GET and seeing if 206 returned
                    try:
                        if self.progress_callback and hasattr(self.progress_callback, 'log_message'):
                            self.progress_callback.log_message("è¿œç«¯è¿”å› Content-Lengthï¼Œå°è¯• Range è¯·æ±‚ä»¥æ ¡éªŒ")
                    except Exception:
                        pass
                    return True

                # Unknown capability
                return None
            except Exception:
                return None

        # è®¾ç½®æ–­ç‚¹ç»­ä¼ çš„è¯·æ±‚å¤´ï¼ˆå¦‚æœé€‚åˆç»­ä¼ ï¼‰
        headers = {}
        if downloaded > 0:
            resume_ok = _head_check_resume(url, downloaded)
            if resume_ok is True:
                headers['Range'] = f'bytes={downloaded}-'
                print(f"å°è¯•ç»­ä¼ : å·²æœ‰ {downloaded} å­—èŠ‚ï¼Œå‡†å¤‡ä» {downloaded} ç»§ç»­ä¸‹è½½")
            elif resume_ok is False:
                # è¿œç«¯æ–‡ä»¶å˜çŸ­æˆ–ä¸ä¸€è‡´ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶å¹¶é‡æ–°å¼€å§‹
                try:
                    os.remove(temp_path)
                except Exception:
                    pass
                downloaded = 0
            else:
                # æœªç¡®å®šæ˜¯å¦æ”¯æŒç»­ä¼ ï¼Œå°è¯• Range: bytes={downloaded}-ï¼Œå¦‚æœæœåŠ¡å™¨è¿”å› 206 åˆ™ç»§ç»­
                headers['Range'] = f'bytes={downloaded}-'
                print("æœªç¡®å®šæ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå°è¯•å‘é€ Range è¯·æ±‚")
        
        # è®°å½•è¦å°è¯•çš„ URLï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
        print(f"å¼€å§‹å•æ¬¡å°è¯•ä¸‹è½½ URL: {url} -> {dest_path}")
        # ä½¿ç”¨åˆ†ç¦»çš„è¶…æ—¶ï¼š(è¿æ¥è¶…æ—¶, è¯»å–è¶…æ—¶)
        # è¿æ¥è¶…æ—¶çŸ­ï¼ˆå¿«é€Ÿå¤±è´¥ï¼‰ï¼Œè¯»å–è¶…æ—¶é•¿ï¼ˆç»™é€Ÿåº¦ç›‘æ§æ—¶é—´ï¼‰
        response = self.session.get(url, stream=True, timeout=(10, 60), headers=headers)
        
        # 416 è¡¨ç¤ºè¯·æ±‚çš„èŒƒå›´æ— æ•ˆï¼ˆæ–‡ä»¶å·²å®Œæ•´ï¼‰
        if response.status_code == 416:
            if os.path.exists(temp_path):
                os.rename(temp_path, dest_path)
            return True
        
        response.raise_for_status()
        
        # å¦‚æœæˆ‘ä»¬è¯·æ±‚äº† `Range` å¹¶å¾—åˆ° 200ï¼Œè¯´æ˜æœåŠ¡å™¨ä¸æ”¯æŒ Rangeï¼Œæ‰€ä»¥éœ€è¦é‡ç½®ï¼ˆåˆ é™¤ tmp å¹¶é‡æ–°è¯·æ±‚å®Œæ•´æ–‡ä»¶ï¼‰
        if downloaded > 0 and response.status_code == 200:
            # æœåŠ¡ç«¯æ²¡æœ‰æŒ‰ Range è¿”å› 206ï¼ˆä¸æ”¯æŒæˆ–å¿½ç•¥ï¼‰ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶å¹¶é‡æ–°å‘èµ·å•æ¬¡è¯·æ±‚
            try:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
            except Exception:
                pass
            # é‡æ–°å‘èµ·æ²¡æœ‰ Range çš„è¯·æ±‚æ¥ä¸‹è½½å®Œæ•´æ–‡ä»¶
            response.close()
            headers.pop('Range', None)
            response = self.session.get(url, stream=True, timeout=(10, 60), headers=headers)

        # è·å–æ–‡ä»¶æ€»å¤§å°
        if 'Content-Range' in response.headers:
            # æ–­ç‚¹ç»­ä¼ ï¼šä» Content-Range ä¸­è§£ææ€»å¤§å°
            total = int(response.headers['Content-Range'].split('/')[-1])
        else:
            # å…¨æ–°ä¸‹è½½
            total = int(response.headers.get('content-length', 0))
        
        # å†™å…¥æ¨¡å¼ï¼šè¿½åŠ æˆ–æ–°å»º
        mode = 'ab' if downloaded > 0 else 'wb'
        
        # é‡ç½®å½“å‰å°è¯•çš„é€Ÿåº¦ç›‘æ§çŠ¶æ€
        if self._current_dlc_state:
            self._current_dlc_state['last_speed_check_time'] = time.time()
            self._current_dlc_state['last_data_time'] = time.time()
        
        stall_threshold = 15  # å¡æ­»é˜ˆå€¼ï¼š15ç§’æ— æ•°æ®ä¼ è¾“
        
        with open(temp_path, mode) as f:
            for chunk in response.iter_content(chunk_size=CHUNK_SIZE):
                # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                if self.stopped:
                    raise Exception("ä¸‹è½½å·²åœæ­¢")
                
                # æ£€æŸ¥æ˜¯å¦æš‚åœ
                while self.paused and not self.stopped:
                    time.sleep(0.1)
                
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    # æ›´æ–°DLCçº§åˆ«çš„çŠ¶æ€
                    if self._current_dlc_state:
                        self._current_dlc_state['total_downloaded'] += len(chunk)
                        self._current_dlc_state['last_data_time'] = time.time()
                    
                    # è°ƒç”¨è¿›åº¦å›è°ƒï¼ˆæ¯æ¬¡æ”¶åˆ°æ•°æ®æ—¶æ›´æ–°ï¼‰
                    if self.progress_callback:
                        try:
                            if total and total > 0:
                                percent = (downloaded / total) * 100
                            else:
                                percent = None
                            # ä¼ é€’ totalï¼ˆå¯èƒ½ä¸º0/Noneï¼‰ä»¥ä¾¿å›è°ƒåšå¯¹åº”å¤„ç†
                            self.progress_callback(percent, downloaded, total)
                        except Exception:
                            # è®°å½•å›è°ƒå†…å¼‚å¸¸ä½†ä¸è¦ä¸­æ–­ä¸‹è½½
                            pass
                    
                    # é€Ÿåº¦ç›‘æ§å’Œæ™ºèƒ½åˆ‡æºï¼ˆåŸºäºå½“å‰DLCçš„çŠ¶æ€ï¼‰
                    current_time = time.time()
                    if self._current_dlc_state and current_time - self._current_dlc_state['last_speed_check_time'] >= self._speed_check_interval:
                        should_switch, new_url, new_source = self._check_speed_and_switch(
                            downloaded, current_time, fallback_urls, current_source_name
                        )
                        
                        if should_switch and new_url:
                            # å…³é—­å½“å‰å“åº”
                            response.close()
                            # æŠ›å‡ºç‰¹æ®Šå¼‚å¸¸ï¼Œè§¦å‘åˆ‡æº
                            raise SpeedTooSlowException(f"é€Ÿåº¦è¿‡æ…¢ï¼Œåˆ‡æ¢åˆ°æº: {new_source}", new_url, new_source)
                else:
                    # æ²¡æœ‰æ”¶åˆ°æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦å¡æ­»
                    if self._current_dlc_state:
                        current_time = time.time()
                        if current_time - self._current_dlc_state['last_data_time'] > stall_threshold:
                            raise Exception(f"ä¸‹è½½å¡æ­»ï¼š{stall_threshold}ç§’æ— æ•°æ®ä¼ è¾“")
        
        # ä¸‹è½½å®Œæˆï¼Œé‡å‘½åä¸´æ—¶æ–‡ä»¶
        if os.path.exists(dest_path):
            os.remove(dest_path)
        os.rename(temp_path, dest_path)
        
        # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        if total > 0:
            actual_size = os.path.getsize(dest_path)
            if actual_size != total:
                raise Exception(f"æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ› {total} å­—èŠ‚ï¼Œå®é™… {actual_size} å­—èŠ‚")
        
        return True

    def _verify_file_hash(self, path: str, expected_hash: str) -> bool:
        """
        éªŒè¯æŒ‡å®šæ–‡ä»¶çš„ SHA256 å“ˆå¸Œæ˜¯å¦ä¸ expected_hash åŒ¹é…
        """
        try:
            import hashlib
            if not expected_hash:
                return True
            expected = expected_hash.strip().lower()
            sha256 = hashlib.sha256()
            with open(path, 'rb') as f:
                for chunk in iter(lambda: f.read(8192), b''):
                    sha256.update(chunk)
            got = sha256.hexdigest().lower()
            if got == expected:
                return True
            else:
                print(f"æ ¡éªŒå¤±è´¥: {path} SHA256 ä¸åŒ¹é… (æœŸæœ› {expected}, å®é™… {got})")
                try:
                    if hasattr(self, 'progress_callback') and getattr(self.progress_callback, 'log_message', None):
                        self.progress_callback.log_message(f"æ ¡éªŒå¤±è´¥: {path} æœŸæœ› {expected}, å®é™… {got}")
                except Exception:
                    pass
                return False
        except Exception as e:
            print(f"éªŒè¯å“ˆå¸Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def download_dlc(self, dlc_key, url, fallback_urls=None, expected_hash: str = None, primary_source_name: str = None):
        """
        ä¸‹è½½DLCåˆ°ç¼“å­˜
        
        å‚æ•°:
            dlc_key: DLCé”®å
            url: ä¸»ä¸‹è½½URL
            fallback_urls: å¤‡ç”¨URLåˆ—è¡¨ (List[Tuple[str, str]] - URLå’Œæºåç§°çš„å…ƒç»„)
            expected_hash: æœŸæœ›çš„SHA256å“ˆå¸Œå€¼ï¼ˆå¯é€‰ï¼‰
            primary_source_name: ä¸»ä¸‹è½½æºåç§°
            
        è¿”å›:
            str: ç¼“å­˜æ–‡ä»¶è·¯å¾„
            
        æŠ›å‡º:
            Exception: ä¸‹è½½å¤±è´¥
        """
        # ä»URLæå–æ–‡ä»¶å
        filename = url.split('/')[-1]
        if not filename:
            filename = f"{dlc_key}.zip"
        cache_path = os.path.join(PathUtils.get_dlc_cache_dir(), filename)
        
        # å¦‚æœç¼“å­˜å·²å­˜åœ¨ï¼ŒéªŒè¯å…¶å®Œæ•´æ€§
        if os.path.exists(cache_path):
            is_valid = self._verify_cached_file(cache_path, expected_hash)
            if is_valid:
                return cache_path
            else:
                # ç¼“å­˜æ–‡ä»¶æŸåï¼Œåˆ é™¤å¹¶é‡æ–°ä¸‹è½½
                self._log_message(f"âš  æ£€æµ‹åˆ°ç¼“å­˜æ–‡ä»¶æŸåï¼Œå°†é‡æ–°ä¸‹è½½: {filename}")
                try:
                    os.remove(cache_path)
                except Exception as e:
                    self._log_message(f"âš  åˆ é™¤æŸåç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
        
        # ä¸‹è½½åˆ°ç¼“å­˜
        self.download(url, cache_path, fallback_urls, expected_hash=expected_hash, primary_source_name=primary_source_name)
        return cache_path
    
    def _verify_cached_file(self, file_path, expected_hash=None):
        """
        éªŒè¯ç¼“å­˜æ–‡ä»¶çš„å®Œæ•´æ€§
        
        å‚æ•°:
            file_path: æ–‡ä»¶è·¯å¾„
            expected_hash: æœŸæœ›çš„SHA256å“ˆå¸Œå€¼ï¼ˆå¯é€‰ï¼‰
            
        è¿”å›:
            bool: æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # 1. æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆè‡³å°‘è¦å¤§äº100å­—èŠ‚ - ä¸€ä¸ªç©ºZIPæœ€å°çº¦22å­—èŠ‚ï¼‰
            file_size = os.path.getsize(file_path)
            if file_size < 100:
                self._log_message(f"âš  ç¼“å­˜æ–‡ä»¶è¿‡å° ({file_size} å­—èŠ‚)ï¼Œå¯èƒ½å·²æŸå")
                return False
            
            # 2. éªŒè¯ZIPæ–‡ä»¶æ ¼å¼
            try:
                import zipfile
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    # æµ‹è¯•ZIPæ–‡ä»¶å®Œæ•´æ€§
                    bad_file = zip_ref.testzip()
                    if bad_file:
                        self._log_message(f"âš  ZIPæ–‡ä»¶æŸåï¼ŒæŸåçš„æ–‡ä»¶: {bad_file}")
                        return False
            except zipfile.BadZipFile:
                self._log_message("âš  ç¼“å­˜æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ZIPæ ¼å¼")
                return False
            except Exception as e:
                self._log_message(f"âš  ZIPéªŒè¯å¤±è´¥: {e}")
                return False
            
            # 3. å¦‚æœæä¾›äº†å“ˆå¸Œå€¼ï¼Œè¿›è¡ŒSHA256æ ¡éªŒ
            if expected_hash:
                import hashlib
                sha256 = hashlib.sha256()
                with open(file_path, 'rb') as f:
                    while True:
                        chunk = f.read(8192)
                        if not chunk:
                            break
                        sha256.update(chunk)
                actual_hash = sha256.hexdigest()
                
                if actual_hash.lower() != expected_hash.lower():
                    self._log_message(f"âš  SHA256æ ¡éªŒå¤±è´¥")
                    self._log_message(f"   æœŸæœ›: {expected_hash}")
                    self._log_message(f"   å®é™…: {actual_hash}")
                    return False
            
            return True
        except Exception as e:
            self._log_message(f"âš  éªŒè¯ç¼“å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def is_cached(self, dlc_key):
        """
        æ£€æŸ¥DLCæ˜¯å¦å·²ç¼“å­˜
        
        å‚æ•°:
            dlc_key: DLCé”®å
            
        è¿”å›:
            bool: æ˜¯å¦å·²ç¼“å­˜
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•ä»¥dlc_keyå¼€å¤´çš„zipæ–‡ä»¶
        cache_dir = PathUtils.get_dlc_cache_dir()
        if not os.path.exists(cache_dir):
            return False
        
        for file in os.listdir(cache_dir):
            if file.startswith(f"{dlc_key}.") and file.endswith('.zip'):
                return True
        return False
